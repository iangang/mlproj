################################
## Hierarchical Clustering
### Data
set.seed(1234)
par(mar = c(0, 0, 0, 0))
x = rnorm(12, mean = rep(1:3, each = 4), sd = 0.2)
y = rnorm(12, mean = rep(c(1, 2, 1), each = 4), sd = 0.2)
plot(x, y, col = "blue", pch = 19, cex = 2)
text(x + 0.05, y + 0.05, labels = as.character(1:12))

### Clustering
dataFrame = data.frame(x = x, y = y)
distxy = dist(dataFrame)

hClustering = hclust(distxy)
plot(hClustering)

myplclust = function(hclust,
                     lab = hclust$labers,
                     lab.col = rep(1, length(hclust$labers)),
                     hang = 0.1, ...){
    y = rep(hclust$height, 2)
    x = as.numeric(hclust$merge)
    y = y[which(x < 0)]
    x = x[which(x < 0)]
    x = abs(x)
    y = y[order(x)]
    x = x[order(x)]
    plot(hclust, labers = FALSE, hang = hang, ...)
    text(x = x, 
         y = y[hclust$order] - (max(hclust$height) * hang), 
         labels = lab[hclust$order], 
         col = lab.col[hclust$order], 
         str = 90, 
         adj = c(1, 0.5), 
         xpd = NA, ...)
}
myplclust(hClustering,
          lab = rep(1:3, each = 4),
          lab.col = rep(1:3, each = 4))

### heatmap()
set.seed(143)
dataMatrix = as.matrix(dataFrame)[sample(1:12), ]
heatmap(dataMatrix)


## K-means Clustering\
### Data
set.seed(1234)
par(mar = c(0, 0, 0, 0))
x = rnorm(12, mean = rep(1:3, each = 4), sd = 0.2)
y = rnorm(12, mean = rep(c(1, 2, 1), each = 4), sd = 0.2)
plot(x, y, col = "blue", pch = 19, cex = 2)
text(x + 0.05, y + 0.05, labels = as.character(1:12))
dataFrame = data.frame(x = x, y = y)

### Clustering
kmeansObj = kmeans(dataFrame, centers = 3)
names(kmeansObj)
kmeansObj$cluster
par(mar = rep(0.2, 4))
plot(x, y, col = kmeansObj$cluster, pch = 19, cex = 2)
text(kmeansObj$centers, col = 1:3, pch = 3, cex = 3, lwd = 3)

### Heatmaps
set.seed(1234)
dataMatrix = as.matrix(dataFrame)[sample(1:12), ]
kmeansObj2 = kmeans(dataMatrix, centers = 3)
par(mfrow = c(1, 2), mar = c(2, 4, 0.1, 0.1))
image(t(dataMatrix)[, nrow(dataMatrix):1], yaxt = "n")
image(t(dataMatrix)[, order(kmeansObj2$cluster)], yaxt = "n")


### Examples
library(caret)
library(ggplot2)
data(iris)
inTrain = createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
training = iris[inTrain, ]
testing = iris[-inTrain, ]
dim(training)
dim(testing)

kMeans1 = kmeans(subset(training, select = -c(Species)), centers = 3)
summary(kMeans1)

training$clusters = as.factor(kMeans1$cluster)

ggplot(data = training, aes(x = Petal.Width, y = Petal.Length, 
                            colour = clusters)) +
    geom_point()

table(kMeans1$cluster, training$Species)

modFit = train(clusters ~ .,
               data = subset(training, select = -c(Species)),
               method = "rpart")
table(predict(modFit, training), training$Species)
testClusterPred = predict(modFit, testing)
table(testClusterPred, testing$Species)


#########################################################################
## K-Means Clustering



