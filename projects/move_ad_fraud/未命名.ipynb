{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data\n",
      "fill null\n",
      "value counts pkgname\n",
      "value counts adunitshowid\n",
      "value counts ip\n",
      "value counts reqrealip\n",
      "value counts adidmd5\n",
      "value counts imeimd5\n",
      "value counts idfamd5\n",
      "value counts macmd5\n",
      "cut\n",
      "cutting pkgname\n",
      "cutting ver\n",
      "cutting reqrealip\n",
      "cutting adidmd5\n",
      "cutting imeimd5\n",
      "cutting openudidmd5\n",
      "cutting macmd5\n",
      "cutting model\n",
      "cutting make\n",
      "cutting ip\n",
      "feature time\n",
      "post process\n",
      "train\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttrain's binary_logloss: 0.360184\ttrain's f1: 0.899665\tval's binary_logloss: 0.363035\tval's f1: 0.897692\n",
      "[20]\ttrain's binary_logloss: 0.267915\ttrain's f1: 0.906452\tval's binary_logloss: 0.270375\tval's f1: 0.90477\n",
      "[30]\ttrain's binary_logloss: 0.23079\ttrain's f1: 0.911015\tval's binary_logloss: 0.232745\tval's f1: 0.909072\n",
      "[40]\ttrain's binary_logloss: 0.212677\ttrain's f1: 0.915174\tval's binary_logloss: 0.214172\tval's f1: 0.913929\n",
      "[50]\ttrain's binary_logloss: 0.201386\ttrain's f1: 0.919074\tval's binary_logloss: 0.202629\tval's f1: 0.918421\n",
      "[60]\ttrain's binary_logloss: 0.194394\ttrain's f1: 0.921433\tval's binary_logloss: 0.196004\tval's f1: 0.920553\n",
      "[70]\ttrain's binary_logloss: 0.189487\ttrain's f1: 0.923134\tval's binary_logloss: 0.191338\tval's f1: 0.922281\n",
      "[80]\ttrain's binary_logloss: 0.185857\ttrain's f1: 0.924445\tval's binary_logloss: 0.187831\tval's f1: 0.923579\n",
      "[90]\ttrain's binary_logloss: 0.182866\ttrain's f1: 0.92566\tval's binary_logloss: 0.184972\tval's f1: 0.925036\n",
      "[100]\ttrain's binary_logloss: 0.180393\ttrain's f1: 0.926461\tval's binary_logloss: 0.18257\tval's f1: 0.925537\n",
      "[110]\ttrain's binary_logloss: 0.178378\ttrain's f1: 0.927337\tval's binary_logloss: 0.180701\tval's f1: 0.926359\n",
      "[120]\ttrain's binary_logloss: 0.176679\ttrain's f1: 0.927841\tval's binary_logloss: 0.179066\tval's f1: 0.926726\n",
      "[130]\ttrain's binary_logloss: 0.175064\ttrain's f1: 0.928514\tval's binary_logloss: 0.177646\tval's f1: 0.927206\n",
      "[140]\ttrain's binary_logloss: 0.173557\ttrain's f1: 0.928969\tval's binary_logloss: 0.17628\tval's f1: 0.927661\n",
      "[150]\ttrain's binary_logloss: 0.172355\ttrain's f1: 0.929447\tval's binary_logloss: 0.175164\tval's f1: 0.928072\n",
      "[160]\ttrain's binary_logloss: 0.171305\ttrain's f1: 0.929869\tval's binary_logloss: 0.174232\tval's f1: 0.928421\n",
      "[170]\ttrain's binary_logloss: 0.17022\ttrain's f1: 0.93033\tval's binary_logloss: 0.173236\tval's f1: 0.928705\n",
      "[180]\ttrain's binary_logloss: 0.169259\ttrain's f1: 0.930679\tval's binary_logloss: 0.172464\tval's f1: 0.928939\n",
      "[190]\ttrain's binary_logloss: 0.168399\ttrain's f1: 0.930976\tval's binary_logloss: 0.171708\tval's f1: 0.929223\n",
      "[200]\ttrain's binary_logloss: 0.16761\ttrain's f1: 0.931277\tval's binary_logloss: 0.171108\tval's f1: 0.929492\n",
      "[210]\ttrain's binary_logloss: 0.166888\ttrain's f1: 0.931586\tval's binary_logloss: 0.170509\tval's f1: 0.929745\n",
      "[220]\ttrain's binary_logloss: 0.16617\ttrain's f1: 0.931868\tval's binary_logloss: 0.169863\tval's f1: 0.930038\n",
      "[230]\ttrain's binary_logloss: 0.165531\ttrain's f1: 0.932114\tval's binary_logloss: 0.169381\tval's f1: 0.930061\n",
      "[240]\ttrain's binary_logloss: 0.164896\ttrain's f1: 0.932334\tval's binary_logloss: 0.168886\tval's f1: 0.930321\n",
      "[250]\ttrain's binary_logloss: 0.164322\ttrain's f1: 0.932581\tval's binary_logloss: 0.168452\tval's f1: 0.930589\n",
      "[260]\ttrain's binary_logloss: 0.163784\ttrain's f1: 0.932734\tval's binary_logloss: 0.168072\tval's f1: 0.930682\n",
      "[270]\ttrain's binary_logloss: 0.163268\ttrain's f1: 0.932949\tval's binary_logloss: 0.167745\tval's f1: 0.930655\n",
      "[280]\ttrain's binary_logloss: 0.162737\ttrain's f1: 0.933135\tval's binary_logloss: 0.167393\tval's f1: 0.930733\n",
      "[290]\ttrain's binary_logloss: 0.162228\ttrain's f1: 0.933303\tval's binary_logloss: 0.167086\tval's f1: 0.930862\n",
      "[300]\ttrain's binary_logloss: 0.161764\ttrain's f1: 0.933468\tval's binary_logloss: 0.166806\tval's f1: 0.931063\n",
      "[310]\ttrain's binary_logloss: 0.16132\ttrain's f1: 0.933658\tval's binary_logloss: 0.166592\tval's f1: 0.930919\n",
      "[320]\ttrain's binary_logloss: 0.160863\ttrain's f1: 0.933844\tval's binary_logloss: 0.166329\tval's f1: 0.931091\n",
      "[330]\ttrain's binary_logloss: 0.160446\ttrain's f1: 0.934001\tval's binary_logloss: 0.166049\tval's f1: 0.931146\n",
      "[340]\ttrain's binary_logloss: 0.160055\ttrain's f1: 0.934213\tval's binary_logloss: 0.16583\tval's f1: 0.931278\n",
      "[350]\ttrain's binary_logloss: 0.159697\ttrain's f1: 0.934329\tval's binary_logloss: 0.16563\tval's f1: 0.931265\n",
      "[360]\ttrain's binary_logloss: 0.159298\ttrain's f1: 0.934442\tval's binary_logloss: 0.16539\tval's f1: 0.931211\n",
      "[370]\ttrain's binary_logloss: 0.158947\ttrain's f1: 0.934573\tval's binary_logloss: 0.165201\tval's f1: 0.93133\n",
      "[380]\ttrain's binary_logloss: 0.158603\ttrain's f1: 0.934671\tval's binary_logloss: 0.164983\tval's f1: 0.931356\n",
      "[390]\ttrain's binary_logloss: 0.158254\ttrain's f1: 0.934799\tval's binary_logloss: 0.164766\tval's f1: 0.931417\n",
      "[400]\ttrain's binary_logloss: 0.157937\ttrain's f1: 0.934865\tval's binary_logloss: 0.164621\tval's f1: 0.931426\n",
      "[410]\ttrain's binary_logloss: 0.157634\ttrain's f1: 0.935007\tval's binary_logloss: 0.164499\tval's f1: 0.931548\n",
      "[420]\ttrain's binary_logloss: 0.157304\ttrain's f1: 0.935107\tval's binary_logloss: 0.164323\tval's f1: 0.931591\n",
      "[430]\ttrain's binary_logloss: 0.157003\ttrain's f1: 0.935191\tval's binary_logloss: 0.164219\tval's f1: 0.931652\n",
      "[440]\ttrain's binary_logloss: 0.156701\ttrain's f1: 0.935357\tval's binary_logloss: 0.164094\tval's f1: 0.931666\n",
      "[450]\ttrain's binary_logloss: 0.15638\ttrain's f1: 0.935455\tval's binary_logloss: 0.163908\tval's f1: 0.931685\n",
      "[460]\ttrain's binary_logloss: 0.156109\ttrain's f1: 0.935561\tval's binary_logloss: 0.16378\tval's f1: 0.931738\n",
      "[470]\ttrain's binary_logloss: 0.155848\ttrain's f1: 0.935656\tval's binary_logloss: 0.163669\tval's f1: 0.931734\n",
      "[480]\ttrain's binary_logloss: 0.155563\ttrain's f1: 0.935749\tval's binary_logloss: 0.163516\tval's f1: 0.931699\n",
      "[490]\ttrain's binary_logloss: 0.155289\ttrain's f1: 0.935843\tval's binary_logloss: 0.163398\tval's f1: 0.931789\n",
      "[500]\ttrain's binary_logloss: 0.155018\ttrain's f1: 0.935944\tval's binary_logloss: 0.1633\tval's f1: 0.931756\n",
      "[510]\ttrain's binary_logloss: 0.154767\ttrain's f1: 0.93607\tval's binary_logloss: 0.163219\tval's f1: 0.931846\n",
      "[520]\ttrain's binary_logloss: 0.154497\ttrain's f1: 0.936159\tval's binary_logloss: 0.163124\tval's f1: 0.931863\n",
      "[530]\ttrain's binary_logloss: 0.15426\ttrain's f1: 0.936245\tval's binary_logloss: 0.16305\tval's f1: 0.931902\n",
      "[540]\ttrain's binary_logloss: 0.154014\ttrain's f1: 0.936303\tval's binary_logloss: 0.162946\tval's f1: 0.931903\n",
      "[550]\ttrain's binary_logloss: 0.153794\ttrain's f1: 0.936369\tval's binary_logloss: 0.162892\tval's f1: 0.932001\n",
      "[560]\ttrain's binary_logloss: 0.153567\ttrain's f1: 0.936466\tval's binary_logloss: 0.162821\tval's f1: 0.932079\n",
      "[570]\ttrain's binary_logloss: 0.153349\ttrain's f1: 0.936526\tval's binary_logloss: 0.162774\tval's f1: 0.932096\n",
      "[580]\ttrain's binary_logloss: 0.153119\ttrain's f1: 0.936682\tval's binary_logloss: 0.162689\tval's f1: 0.932043\n",
      "[590]\ttrain's binary_logloss: 0.152883\ttrain's f1: 0.936789\tval's binary_logloss: 0.162591\tval's f1: 0.932034\n",
      "[600]\ttrain's binary_logloss: 0.152673\ttrain's f1: 0.936923\tval's binary_logloss: 0.162518\tval's f1: 0.932109\n",
      "[610]\ttrain's binary_logloss: 0.152461\ttrain's f1: 0.937012\tval's binary_logloss: 0.162446\tval's f1: 0.932122\n",
      "[620]\ttrain's binary_logloss: 0.152233\ttrain's f1: 0.937044\tval's binary_logloss: 0.162359\tval's f1: 0.932292\n",
      "[630]\ttrain's binary_logloss: 0.152018\ttrain's f1: 0.937144\tval's binary_logloss: 0.162279\tval's f1: 0.932272\n",
      "[640]\ttrain's binary_logloss: 0.151802\ttrain's f1: 0.937228\tval's binary_logloss: 0.162216\tval's f1: 0.932297\n",
      "[650]\ttrain's binary_logloss: 0.151586\ttrain's f1: 0.937365\tval's binary_logloss: 0.162164\tval's f1: 0.932337\n",
      "[660]\ttrain's binary_logloss: 0.151364\ttrain's f1: 0.937431\tval's binary_logloss: 0.162099\tval's f1: 0.932476\n",
      "[670]\ttrain's binary_logloss: 0.151154\ttrain's f1: 0.937523\tval's binary_logloss: 0.162052\tval's f1: 0.932342\n",
      "[680]\ttrain's binary_logloss: 0.150959\ttrain's f1: 0.937588\tval's binary_logloss: 0.161982\tval's f1: 0.932386\n",
      "[690]\ttrain's binary_logloss: 0.150741\ttrain's f1: 0.937698\tval's binary_logloss: 0.161893\tval's f1: 0.932413\n",
      "[700]\ttrain's binary_logloss: 0.150528\ttrain's f1: 0.937783\tval's binary_logloss: 0.161825\tval's f1: 0.932336\n",
      "[710]\ttrain's binary_logloss: 0.150331\ttrain's f1: 0.937863\tval's binary_logloss: 0.161802\tval's f1: 0.932352\n",
      "[720]\ttrain's binary_logloss: 0.150137\ttrain's f1: 0.937916\tval's binary_logloss: 0.161765\tval's f1: 0.932448\n",
      "[730]\ttrain's binary_logloss: 0.149941\ttrain's f1: 0.938018\tval's binary_logloss: 0.161707\tval's f1: 0.932465\n",
      "[740]\ttrain's binary_logloss: 0.149766\ttrain's f1: 0.9381\tval's binary_logloss: 0.16166\tval's f1: 0.932463\n",
      "[750]\ttrain's binary_logloss: 0.14956\ttrain's f1: 0.938168\tval's binary_logloss: 0.161592\tval's f1: 0.932545\n",
      "[760]\ttrain's binary_logloss: 0.149373\ttrain's f1: 0.938219\tval's binary_logloss: 0.161544\tval's f1: 0.932613\n",
      "[770]\ttrain's binary_logloss: 0.149171\ttrain's f1: 0.938298\tval's binary_logloss: 0.161494\tval's f1: 0.932575\n",
      "[780]\ttrain's binary_logloss: 0.14898\ttrain's f1: 0.938396\tval's binary_logloss: 0.161446\tval's f1: 0.932469\n",
      "[790]\ttrain's binary_logloss: 0.148818\ttrain's f1: 0.938436\tval's binary_logloss: 0.161426\tval's f1: 0.932413\n",
      "[800]\ttrain's binary_logloss: 0.148637\ttrain's f1: 0.93853\tval's binary_logloss: 0.161385\tval's f1: 0.93241\n",
      "[810]\ttrain's binary_logloss: 0.148451\ttrain's f1: 0.938554\tval's binary_logloss: 0.161351\tval's f1: 0.932411\n",
      "[820]\ttrain's binary_logloss: 0.148281\ttrain's f1: 0.938664\tval's binary_logloss: 0.161292\tval's f1: 0.932426\n",
      "[830]\ttrain's binary_logloss: 0.148109\ttrain's f1: 0.9387\tval's binary_logloss: 0.161254\tval's f1: 0.93243\n",
      "[840]\ttrain's binary_logloss: 0.147936\ttrain's f1: 0.938736\tval's binary_logloss: 0.161225\tval's f1: 0.932426\n",
      "[850]\ttrain's binary_logloss: 0.147761\ttrain's f1: 0.938811\tval's binary_logloss: 0.16118\tval's f1: 0.932476\n",
      "[860]\ttrain's binary_logloss: 0.147593\ttrain's f1: 0.938873\tval's binary_logloss: 0.161144\tval's f1: 0.932525\n",
      "Early stopping, best iteration is:\n",
      "[766]\ttrain's binary_logloss: 0.149257\ttrain's f1: 0.938276\tval's binary_logloss: 0.161519\tval's f1: 0.932633\n",
      "best score defaultdict(<class 'dict'>, {'train': {'binary_logloss': 0.1492574447586741, 'f1': 0.9382756071624165}, 'val': {'binary_logloss': 0.1615189209679594, 'f1': 0.9326325582687061}})\n"
     ]
    }
   ],
   "source": [
    "# %%-------------------------------\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.feature_selection import chi2, SelectPercentile\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "from lightgbm import LGBMClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# %%-------------------------------\n",
    "print(\"read data\")\n",
    "path = \"/Users/zfwang/data/mldata/aichallenge_2019_ad_fraud/data/\"\n",
    "df_train = pd.read_csv(path + \"round1_iflyad_anticheat_traindata.txt\", sep = \"\\t\")\n",
    "df_test = pd.read_csv(path + \"round1_iflyad_anticheat_testdata_feature.txt\", sep = \"\\t\")\n",
    "df_uni = pd.concat([df_train, df_test], ignore_index = True)\n",
    "df_uni[\"label\"] = df_uni[\"label\"].fillna(-1).astype(int)\n",
    "\n",
    "# %%-------------------------------\n",
    "\n",
    "cat_cols = ['pkgname', 'ver', 'adunitshowid', 'mediashowid', 'apptype', 'ip',\n",
    "            'reqrealip', 'city', 'province', 'adidmd5', 'imeimd5', 'idfamd5',\n",
    "            'openudidmd5', 'macmd5', 'dvctype', 'model', 'make', 'ntt',\n",
    "            'carrier', 'os', 'osv', 'orientation', 'lan', 'h', 'w', 'ppi']\n",
    "drop_cols = ['sid', 'label', 'nginxtime']\n",
    "\n",
    "# %%-------------------------------\n",
    "print('fill null')\n",
    "for cat_col in cat_cols:\n",
    "    if df_uni[cat_col].isnull().sum() > 0:\n",
    "        df_uni[cat_col].fillna('null_value', inplace=True)\n",
    "\n",
    "\n",
    "# %%-------------------------------\n",
    "def gen_value_counts(data, col):\n",
    "    print('value counts', col)\n",
    "    df_tmp = pd.DataFrame(data[col].value_counts().reset_index())\n",
    "    df_tmp.columns = [col, 'tmp']\n",
    "    r = pd.merge(data, df_tmp, how='left', on=col)['tmp']\n",
    "    return r.fillna(0)\n",
    "\n",
    "value_counts_col = ['pkgname', 'adunitshowid', 'ip', 'reqrealip',\n",
    "                    'adidmd5', 'imeimd5', 'idfamd5', 'macmd5']\n",
    "\n",
    "for col in value_counts_col:\n",
    "    df_uni['vc_' + col] = gen_value_counts(df_uni, col)\n",
    "\n",
    "# %%-------------------------------\n",
    "print('cut')\n",
    "def cut_col(data, col_name, cut_list):\n",
    "    print('cutting', col_name)\n",
    "\n",
    "    def _trans(array):\n",
    "        count = array['box_counts']\n",
    "        for box in cut_list:\n",
    "            if count <= box:\n",
    "                return 'count_' + str(box)\n",
    "        return array[col_name]\n",
    "\n",
    "    df_counts = pd.DataFrame(data[col_name].value_counts())\n",
    "    df_counts.columns = ['box_counts']\n",
    "    df_counts[col_name] = df_counts.index\n",
    "    df = pd.merge(data, df_counts, on=col_name, how='left')\n",
    "    column = df.apply(_trans, axis=1)\n",
    "    return column\n",
    "\n",
    "\n",
    "cut_col_dict = {\n",
    "    ('pkgname', 'ver', 'reqrealip', 'adidmd5',\n",
    "     'imeimd5', 'openudidmd5', 'macmd5', 'model', 'make'): [3],\n",
    "    ('ip',): [3, 5, 10],\n",
    "}\n",
    "\n",
    "for cut_cols, cut_list in cut_col_dict.items():\n",
    "    for col in cut_cols:\n",
    "        df_uni[col] = cut_col(df_uni, col, cut_list)\n",
    "\n",
    "# %%-------------------------------\n",
    "print('feature time')\n",
    "df_uni['datetime'] = pd.to_datetime(df_uni['nginxtime'] / 1000, unit='s') + timedelta(hours=8)\n",
    "df_uni['hour'] = df_uni['datetime'].dt.hour\n",
    "df_uni['day'] = df_uni['datetime'].dt.day - df_uni['datetime'].dt.day.min()\n",
    "\n",
    "cat_cols += ['hour']\n",
    "drop_cols += ['datetime', 'day']\n",
    "\n",
    "# %%-------------------------------\n",
    "print('post process')\n",
    "for col in cat_cols:\n",
    "    df_uni[col] = df_uni[col].map(dict(zip(df_uni[col].unique(), range(0, df_uni[col].nunique()))))\n",
    "\n",
    "all_train_index = (df_uni['day'] <= 6).values\n",
    "train_index     = (df_uni['day'] <= 5).values\n",
    "valid_index     = (df_uni['day'] == 6).values\n",
    "test_index      = (df_uni['day'] == 7).values\n",
    "train_label     = (df_uni['label']).values\n",
    "\n",
    "for col in drop_cols:\n",
    "    if col in df_uni.columns:\n",
    "        df_uni.drop([col], axis=1, inplace=True)\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "mtx_cat = ohe.fit_transform(df_uni[cat_cols])\n",
    "num_cols = list(set(df_uni.columns).difference(set(cat_cols)))\n",
    "mtx_num = sparse.csr_matrix(df_uni[num_cols].astype(float).values)\n",
    "mtx_uni = sparse.hstack([mtx_num, mtx_cat])\n",
    "mtx_uni = mtx_uni.tocsr()\n",
    "\n",
    "def col_filter(mtx_train, y_train, mtx_test, func=chi2, percentile=90):\n",
    "    feature_select = SelectPercentile(func, percentile=percentile)\n",
    "    feature_select.fit(mtx_train, y_train)\n",
    "    mtx_train = feature_select.transform(mtx_train)\n",
    "    mtx_test = feature_select.transform(mtx_test)\n",
    "    return mtx_train, mtx_test\n",
    "\n",
    "all_train_x, test_x = col_filter(\n",
    "    mtx_uni[all_train_index, :],\n",
    "    train_label[all_train_index],\n",
    "    mtx_uni[test_index, :]\n",
    ")\n",
    "\n",
    "\n",
    "train_x = all_train_x[train_index[:all_train_x.shape[0]], :]\n",
    "train_y = train_label[train_index]\n",
    "\n",
    "val_x = all_train_x[valid_index[:all_train_x.shape[0]], :]\n",
    "val_y = train_label[valid_index]\n",
    "\n",
    "# %%-------------------------------\n",
    "print('train')\n",
    "def lgb_f1(labels, preds):\n",
    "    score = f1_score(labels, np.round(preds))\n",
    "    return 'f1', score, True\n",
    "\n",
    "lgb = LGBMClassifier(random_seed=2019, n_jobs=-1, objective='binary',\n",
    "                     learning_rate=0.1, n_estimators=4000, num_leaves=64, max_depth=-1,\n",
    "                     min_child_samples=20, min_child_weight=9, subsample_freq=1,\n",
    "                     subsample=0.8, colsample_bytree=0.8, reg_alpha=1, reg_lambda=5)\n",
    "\n",
    "lgb.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    eval_set=[(train_x, train_y), (val_x, val_y)],\n",
    "    eval_names=['train', 'val'],\n",
    "    eval_metric=lgb_f1,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=10,\n",
    ")\n",
    "print('best score', lgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
