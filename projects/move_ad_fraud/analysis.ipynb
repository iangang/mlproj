{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.导入工具库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data\n"
     ]
    }
   ],
   "source": [
    "print(\"read data\")\n",
    "path = \"/Users/zfwang/data/mldata/aichallenge_2019_ad_fraud/data/\"\n",
    "df_train = pd.read_csv(path + \"round1_iflyad_anticheat_traindata.txt\", sep = \"\\t\")\n",
    "df_test = pd.read_csv(path + \"round1_iflyad_anticheat_testdata_feature.txt\", sep = \"\\t\")\n",
    "df_uni = pd.concat([df_train, df_test], ignore_index = True)\n",
    "df_uni[\"label\"] = df_uni[\"label\"].fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 类别型特征和无用特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['pkgname', 'ver', 'adunitshowid', 'mediashowid', 'apptype', 'ip',\n",
    "            'reqrealip', 'city', 'province', 'adidmd5', 'imeimd5', 'idfamd5',\n",
    "            'openudidmd5', 'macmd5', 'dvctype', 'model', 'make', 'ntt',\n",
    "            'carrier', 'os', 'osv', 'orientation', 'lan', 'h', 'w', 'ppi']\n",
    "drop_cols = ['sid', 'label', 'nginxtime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 缺失值填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill null\n"
     ]
    }
   ],
   "source": [
    "# 对含有缺失值的特征用`null_value`进行填充\n",
    "print('fill null')\n",
    "for cat_col in cat_cols:\n",
    "    if df_uni[cat_col].isnull().sum() > 0:\n",
    "        df_uni[cat_col].fillna('null_value', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 生成特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate some features:\n",
      "value counts pkgname\n",
      "value counts adunitshowid\n",
      "value counts ip\n",
      "value counts reqrealip\n",
      "value counts adidmd5\n",
      "value counts imeimd5\n",
      "value counts idfamd5\n",
      "value counts macmd5\n"
     ]
    }
   ],
   "source": [
    "print(\"generate some features:\")\n",
    "def gen_value_counts(data, col):\n",
    "    print('value counts', col)\n",
    "    df_tmp = pd.DataFrame(data[col].value_counts().reset_index())\n",
    "    df_tmp.columns = [col, 'tmp']\n",
    "    r = pd.merge(data, df_tmp, how = 'left', on = col)['tmp']\n",
    "    return r.fillna(0)\n",
    "\n",
    "value_counts_col = ['pkgname', 'adunitshowid', 'ip', 'reqrealip',\n",
    "                    'adidmd5', 'imeimd5', 'idfamd5', 'macmd5']\n",
    "\n",
    "for col in value_counts_col:\n",
    "    df_uni['vc_' + col] = gen_value_counts(df_uni, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 日期特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut:\n",
      "cutting pkgname\n",
      "cutting ver\n",
      "cutting reqrealip\n",
      "cutting adidmd5\n",
      "cutting imeimd5\n",
      "cutting openudidmd5\n",
      "cutting macmd5\n",
      "cutting model\n",
      "cutting make\n",
      "cutting ip\n"
     ]
    }
   ],
   "source": [
    "print('cut:')\n",
    "def cut_col(data, col_name, cut_list):\n",
    "    print('cutting', col_name)\n",
    "\n",
    "    def _trans(array):\n",
    "        count = array['box_counts']\n",
    "        for box in cut_list:\n",
    "            if count <= box:\n",
    "                return 'count_' + str(box)\n",
    "        return array[col_name]\n",
    "\n",
    "    df_counts = pd.DataFrame(data[col_name].value_counts())\n",
    "    df_counts.columns = ['box_counts']\n",
    "    df_counts[col_name] = df_counts.index\n",
    "    df = pd.merge(data, df_counts, on = col_name, how = 'left')\n",
    "    column = df.apply(_trans, axis = 1)\n",
    "    return column\n",
    "\n",
    "cut_col_dict = {\n",
    "    ('pkgname', 'ver', 'reqrealip', 'adidmd5', 'imeimd5', 'openudidmd5', 'macmd5', 'model', 'make'): [3],\n",
    "    ('ip',): [3, 5, 10],\n",
    "}\n",
    "\n",
    "for cut_cols, cut_list in cut_col_dict.items():\n",
    "    for col in cut_cols:\n",
    "        df_uni[col] = cut_col(df_uni, col, cut_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature time\n"
     ]
    }
   ],
   "source": [
    "print('feature time')\n",
    "df_uni['datetime'] = pd.to_datetime(df_uni['nginxtime'] / 1000, unit='s') + timedelta(hours=8)\n",
    "df_uni['hour'] = df_uni['datetime'].dt.hour\n",
    "df_uni['day'] = df_uni['datetime'].dt.day - df_uni['datetime'].dt.day.min()\n",
    "\n",
    "cat_cols += ['hour']\n",
    "drop_cols += ['datetime', 'day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('post process')\n",
    "for col in cat_cols:\n",
    "    df_uni[col] = df_uni[col].map(dict(zip(df_uni[col].unique(), range(0, df_uni[col].nunique()))))\n",
    "\n",
    "all_train_index = (df_uni['day'] <= 6).values\n",
    "train_index     = (df_uni['day'] <= 5).values\n",
    "valid_index     = (df_uni['day'] == 6).values\n",
    "test_index      = (df_uni['day'] == 7).values\n",
    "train_label     = (df_uni['label']).values\n",
    "\n",
    "for col in drop_cols:\n",
    "    if col in df_uni.columns:\n",
    "        df_uni.drop([col], axis=1, inplace=True)\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "mtx_cat = ohe.fit_transform(df_uni[cat_cols])\n",
    "num_cols = list(set(df_uni.columns).difference(set(cat_cols)))\n",
    "mtx_num = sparse.csr_matrix(df_uni[num_cols].astype(float).values)\n",
    "mtx_uni = sparse.hstack([mtx_num, mtx_cat])\n",
    "mtx_uni = mtx_uni.tocsr()\n",
    "\n",
    "def col_filter(mtx_train, y_train, mtx_test, func=chi2, percentile=90):\n",
    "    feature_select = SelectPercentile(func, percentile=percentile)\n",
    "    feature_select.fit(mtx_train, y_train)\n",
    "    mtx_train = feature_select.transform(mtx_train)\n",
    "    mtx_test = feature_select.transform(mtx_test)\n",
    "    return mtx_train, mtx_test\n",
    "\n",
    "all_train_x, test_x = col_filter(\n",
    "    mtx_uni[all_train_index, :],\n",
    "    train_label[all_train_index],\n",
    "    mtx_uni[test_index, :]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################################################\n",
    "# 模型数据准备\n",
    "# #################################################\n",
    "train_x = all_train_x[train_index[:all_train_x.shape[0]], :]\n",
    "train_y = train_label[train_index]\n",
    "\n",
    "val_x = all_train_x[valid_index[:all_train_x.shape[0]], :]\n",
    "val_y = train_label[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################################################\n",
    "# 模型训练\n",
    "# #################################################\n",
    "print('train')\n",
    "def lgb_f1(labels, preds):\n",
    "    score = f1_score(labels, np.round(preds))\n",
    "    return 'f1', score, True\n",
    "\n",
    "lgb = LGBMClassifier(random_seed=2019, n_jobs=-1, objective='binary',\n",
    "                     learning_rate=0.1, n_estimators=4000, num_leaves=64, max_depth=-1,\n",
    "                     min_child_samples=20, min_child_weight=9, subsample_freq=1,\n",
    "                     subsample=0.8, colsample_bytree=0.8, reg_alpha=1, reg_lambda=5)\n",
    "\n",
    "lgb.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    eval_set=[(train_x, train_y), (val_x, val_y)],\n",
    "    eval_names=['train', 'val'],\n",
    "    eval_metric=lgb_f1,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=10,\n",
    ")\n",
    "print('best score', lgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################################################      \n",
    "# 模型预测\n",
    "# #################################################\n",
    "print(\"predict\")\n",
    "all_train_y = train_label[all_train_index]\n",
    "lgb.n_estimators = lgb.best_iteration_\n",
    "lgb.fit(all_train_x, all_train_y)\n",
    "test_y = lgb.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "print(\"generate submission file\")\n",
    "df_sub = pd.concat([df_test[\"sid\"], pd.Series(test_y)], axis = 1)\n",
    "df_sub.columns = [\"sid\", \"label\"]\n",
    "df_sub.to_csv(\"submit-{}.csv\".format(datetime.now().strftime(\"%m%d_%H%M%S\")), \n",
    "              sep = \",\", \n",
    "              index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
